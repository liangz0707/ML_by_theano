{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This tutorial introduces denoising auto-encoders (dA) using Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这篇文章是为了SdA的实现做准备的.\n",
    "实际上dA和mlp都含有输入层、隐藏层、和输出层，唯一的区别是，dA使用了$W^T$作为了输出层的权重。这样做所隐含的意义：```是为了把输入x通过隐藏层变为y，再通过输出层还原成x```。通过这一组非线性变换可以学习到重要的主分量。\n",
    "他和PCA的区别在于，dA是非线性的，而PCA是线性的。（由于增加了sigmod过程）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码的过程为：\n",
    "$$y = f_{\\theta}(x) = s(Wx+b)$$\n",
    "解码的过程为：\n",
    "$$z = g_{\\theta'}(y) = s(W'y + b')$$\n",
    "值得范围：\n",
    "$$z,x \\in [0,1]^d$$\n",
    "W可以进行约束：$W' = W^T$\n",
    "梯度的误差可以写作：\n",
    "$$\\sum_{k=1}^d[ x_k \\log z_k + (1-x_k) \\log( 1-z_k)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文献 :\n",
    "   - P. Vincent, H. Larochelle, Y. Bengio, P.A. Manzagol: Extracting and\n",
    "   Composing Robust Features with Denoising Autoencoders, ICML'08, 1096-1103,\n",
    "   2008\n",
    "   - Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle: Greedy Layer-Wise\n",
    "   Training of Deep Networks, Advances in Neural Information Processing\n",
    "   Systems 19, 2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "引入必要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "import cPickle\n",
    "import gzip\n",
    "\n",
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "uitl这个单元并不是通过pip install安装的模块，而是一个在Deeplearing.net里面的py文件。具体可以在Github上搜索DeepLearningTutorials，使用里面的utils.py文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import tile_raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import PIL.Image as Image\n",
    "except ImportError:\n",
    "    import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义dA类\n",
    "$$y = s(W \\tilde{x} + b)$$\n",
    "$$x = s(W' y  + b') $$\n",
    "$$L(x,z) = -sum_{k=1}^d [x_k \\log z_k + (1-x_k) \\log( 1-z_k)]  $$\n",
    "W的随机初始值：\n",
    "$$ W\\in (-4*sqrt(\\frac{6.}{n_visible+n_hidden}) , 4*sqrt(\\frac{6.}{n_hidden+n_visible}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class dA(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        numpy_rng,\n",
    "        theano_rng=None,\n",
    "        input=None,\n",
    "        n_visible=784,\n",
    "        n_hidden=500,\n",
    "        W=None,\n",
    "        bhid=None,\n",
    "        bvis=None\n",
    "    ):\n",
    "        #利用初始值进行赋值\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        if not theano_rng:\n",
    "            theano_rng = RandomStreams(numpy_rng.randint(2 ** 30))\n",
    "\n",
    "        if not W:\n",
    "            #W如果没有给定则随机赋值\n",
    "            initial_W = numpy.asarray(\n",
    "                numpy_rng.uniform(\n",
    "                    low=-4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
    "                    high=4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
    "                    size=(n_visible, n_hidden)\n",
    "                ),\n",
    "                dtype=theano.config.floatX\n",
    "            )\n",
    "            W = theano.shared(value=initial_W, name='W', borrow=True)\n",
    "        #bias值为0即可\n",
    "        if not bvis:\n",
    "            bvis = theano.shared(\n",
    "                value=numpy.zeros(\n",
    "                    n_visible,\n",
    "                    dtype=theano.config.floatX\n",
    "                ),\n",
    "                borrow=True\n",
    "            )\n",
    "\n",
    "        if not bhid:\n",
    "            bhid = theano.shared(\n",
    "                value=numpy.zeros(\n",
    "                    n_hidden,\n",
    "                    dtype=theano.config.floatX\n",
    "                ),\n",
    "                name='b',\n",
    "                borrow=True\n",
    "            )\n",
    "\n",
    "        self.W = W\n",
    "        self.b = bhid\n",
    "        self.b_prime = bvis\n",
    " \n",
    "        self.W_prime = self.W.T\n",
    "        #这也是一个随机量，但是他的生成和rng不同，它是专门提供shared的随机变量。\n",
    "        self.theano_rng = theano_rng\n",
    "        #记录输入的符号\n",
    "        if input is None:\n",
    "            self.x = T.dmatrix(name='input')\n",
    "        else:\n",
    "            self.x = input\n",
    "        #保存要梯度下降的参数。\n",
    "        self.params = [self.W, self.b, self.b_prime]\n",
    "    #制造干扰参数，生成一组随机的干扰\n",
    "    '''\n",
    "        解释：如果只是用最小重构误差来进行约束的话，那么只不过是将输入映射成它本身而已。\n",
    "        解决方法：1.使用稀疏，2.使用随机噪声（本文方法）\n",
    "        解释：使用噪声是为了让隐藏层发现更多具有鲁棒性的特征。\n",
    "    '''\n",
    "    def get_corrupted_input(self, input, corruption_level):\n",
    "        #这就是一个二项分布函数，让部分输入变成0\n",
    "        return self.theano_rng.binomial(size=input.shape, n=1,\n",
    "                                        p=1 - corruption_level,\n",
    "                                        dtype=theano.config.floatX) * input\n",
    "    #得到隐藏层的值，也就是y\n",
    "    def get_hidden_values(self, input):\n",
    "        return T.nnet.sigmoid(T.dot(input, self.W) + self.b)\n",
    "    #得到输出层的值，也就是由y还原的z\n",
    "    def get_reconstructed_input(self, hidden):\n",
    "        return T.nnet.sigmoid(T.dot(hidden, self.W_prime) + self.b_prime)\n",
    "    #误差更新，也就是梯度下降的过程\n",
    "    def get_cost_updates(self, corruption_level, learning_rate):\n",
    "\n",
    "        tilde_x = self.get_corrupted_input(self.x, corruption_level)\n",
    "        y = self.get_hidden_values(tilde_x)\n",
    "        z = self.get_reconstructed_input(y)\n",
    "        #计算交叉熵\n",
    "        L = - T.sum(self.x * T.log(z) + (1 - self.x) * T.log(1 - z), axis=1)\n",
    "\n",
    "        cost = T.mean(L)\n",
    "\n",
    "        #计算梯度\n",
    "        gparams = T.grad(cost, self.params)\n",
    "        #生成梯度下降列表\n",
    "        updates = [\n",
    "            (param, param - learning_rate * gparam)\n",
    "            for param, gparam in zip(self.params, gparams)\n",
    "        ]\n",
    "        #返回混杂熵，和梯度下降列表\n",
    "        return (cost, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_dA(learning_rate=0.1, training_epochs=15,\n",
    "            dataset='mnist.pkl.gz',\n",
    "            batch_size=20, output_folder='dA_plots'):\n",
    "\n",
    "    \"\"\"\n",
    "    同样是在手写数据集当中测试\n",
    "\n",
    "    让后给出迭代次数 和每次使用的 训练样本数。\n",
    "\n",
    "    \"\"\"\n",
    "    datasets = load_data(dataset)\n",
    "    train_set_x, train_set_y = datasets[0]\n",
    "\n",
    "    #计算每次迭代的训练次数。\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "\n",
    "    #索引作为输入，用于指向当前的训练batch\n",
    "    index = T.lscalar() \n",
    "    #确定输入的类型\n",
    "    x = T.matrix('x') \n",
    "    \n",
    "    #结果文件建立\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    os.chdir(output_folder)\n",
    "\n",
    "    ####################################\n",
    "    # BUILDING THE MODEL NO CORRUPTION #\n",
    "    ####################################\n",
    "\n",
    "    rng = numpy.random.RandomState(123)\n",
    "    theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "\n",
    "    da = dA(\n",
    "        numpy_rng=rng,\n",
    "        theano_rng=theano_rng,\n",
    "        input=x,\n",
    "        n_visible=28 * 28,\n",
    "        n_hidden=500\n",
    "    )\n",
    "\n",
    "    cost, updates = da.get_cost_updates(\n",
    "        corruption_level=0.,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    train_da = theano.function(\n",
    "        [index],\n",
    "        cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    ############\n",
    "    # TRAINING #\n",
    "    ############\n",
    "\n",
    "    # go through training epochs\n",
    "    for epoch in xrange(training_epochs):\n",
    "        # go through trainng set\n",
    "        c = []\n",
    "        for batch_index in xrange(n_train_batches):\n",
    "            c.append(train_da(batch_index))\n",
    "\n",
    "        print 'Training epoch %d, cost ' % epoch, numpy.mean(c)\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "\n",
    "    training_time = (end_time - start_time)\n",
    "\n",
    "    print >> sys.stderr, ('The no corruption code for file ' +\n",
    "                          ' ran for %.2fm' % ((training_time) / 60.))\n",
    "    image = Image.fromarray(\n",
    "        tile_raster_images(X=da.W.get_value(borrow=True).T,\n",
    "                           img_shape=(28, 28), tile_shape=(10, 10),\n",
    "                           tile_spacing=(1, 1)))\n",
    "    image.save('filters_corruption_0.png')\n",
    "\n",
    "    # start-snippet-3\n",
    "    #####################################\n",
    "    # BUILDING THE MODEL CORRUPTION 30% #\n",
    "    #####################################\n",
    "\n",
    "    rng = numpy.random.RandomState(123)\n",
    "    theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "\n",
    "    da = dA(\n",
    "        numpy_rng=rng,\n",
    "        theano_rng=theano_rng,\n",
    "        input=x,\n",
    "        n_visible=28 * 28,\n",
    "        n_hidden=500\n",
    "    )\n",
    "    #唯一给变的地方就是这里，修改了坍塌\n",
    "    cost, updates = da.get_cost_updates(\n",
    "        corruption_level=0.3,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    train_da = theano.function(\n",
    "        [index],\n",
    "        cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    ############\n",
    "    # TRAINING #\n",
    "    ############\n",
    "\n",
    "    # go through training epochs\n",
    "    for epoch in xrange(training_epochs):\n",
    "        # go through trainng set\n",
    "        c = []\n",
    "        for batch_index in xrange(n_train_batches):\n",
    "            c.append(train_da(batch_index))\n",
    "\n",
    "        print 'Training epoch %d, cost ' % epoch, numpy.mean(c)\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "\n",
    "    training_time = (end_time - start_time)\n",
    "\n",
    "    print >> sys.stderr, ('The 30% corruption code for file ' +\n",
    "                          ' ran for %.2fm' % (training_time / 60.))\n",
    "    # end-snippet-3\n",
    "\n",
    "    # start-snippet-4\n",
    "    image = Image.fromarray(tile_raster_images(\n",
    "        X=da.W.get_value(borrow=True).T,\n",
    "        img_shape=(28, 28), tile_shape=(10, 20),\n",
    "        tile_spacing=(1, 1)))\n",
    "    image.save('filters_corruption_30.png')\n",
    "    # end-snippet-4\n",
    "\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    # Download the MNIST dataset if it is not present\n",
    "    data_dir, data_file = os.path.split(dataset)\n",
    "\n",
    "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "        # Check if dataset is in the data directory.\n",
    "        new_path = os.path.join(\n",
    "            dataset\n",
    "        )\n",
    "        \n",
    "        if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "            dataset = new_path\n",
    "\n",
    "    if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "        import urllib\n",
    "        origin = (\n",
    "            'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "        )\n",
    "        print 'Downloading data from %s' % origin\n",
    "        urllib.urlretrieve(origin, dataset)\n",
    "\n",
    "    f = gzip.open(dataset, 'rb')\n",
    "    train_set, valid_set, test_set = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    def shared_dataset(data_xy, borrow=True):\n",
    "\n",
    "        data_x, data_y = data_xy\n",
    "        shared_x = theano.shared(numpy.asarray(data_x,\n",
    "                                               dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "        shared_y = theano.shared(numpy.asarray(data_y,\n",
    "                                               dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "\n",
    "        return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "    test_set_x, test_set_y = shared_dataset(test_set)\n",
    "    valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "    train_set_x, train_set_y = shared_dataset(train_set)\n",
    "\n",
    "    rval = [(train_set_x, train_set_y), (valid_set_x, valid_set_y),\n",
    "            (test_set_x, test_set_y)]\n",
    "    return rval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0, cost  63.2892\n",
      "Training epoch 1, cost  55.7867\n",
      "Training epoch 2, cost  54.7631\n",
      "Training epoch 3, cost  54.2421\n",
      "Training epoch 4, cost  53.8887\n",
      "Training epoch 5, cost  53.6203\n",
      "Training epoch 6, cost  53.4038\n",
      "Training epoch 7, cost  53.222\n",
      "Training epoch 8, cost  53.0658\n",
      "Training epoch 9, cost  52.9296\n",
      "Training epoch 10, cost  52.8094\n",
      "Training epoch 11, cost  52.7024\n",
      "Training epoch 12, cost  52.6063\n",
      "Training epoch 13, cost  52.5192\n",
      "Training epoch 14, cost  52.4395\n",
      "Training epoch 0, cost  81.7714\n",
      "Training epoch 1, cost  73.4286\n",
      "Training epoch 2, cost  70.8633\n",
      "Training epoch 3, cost  69.3397\n",
      "Training epoch 4, cost  68.4135\n",
      "Training epoch 5, cost  67.7237\n",
      "Training epoch 6, cost  67.2401\n",
      "Training epoch 7, cost  66.8493\n",
      "Training epoch 8, cost  66.5664\n",
      "Training epoch 9, cost  66.3591\n",
      "Training epoch 10, cost  66.1337\n",
      "Training epoch 11, cost  65.9894\n",
      "Training epoch 12, cost  65.8344\n",
      "Training epoch 13, cost  65.7185\n",
      "Training epoch 14, cost "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The no corruption code for file  ran for 4.89m\n",
      "The 30% corruption code for file  ran for 3.86m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65.6011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
