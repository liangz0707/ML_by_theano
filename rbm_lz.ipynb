{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Restricted Boltzmann Machines (RBM)\n",
    "\n",
    "首先需要具备的知识：\n",
    "- 玻尔兹曼机\n",
    "- 二部图\n",
    "- sigmoid函数\n",
    "- Bayes定理\n",
    "- 蒙塔卡罗方法\n",
    "- 马尔科夫链\n",
    "- MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Energy-Based Models (EBM) \n",
    "给予能量的模型就是通过一些属性，计算出一个标量的能量。我们通过学习将能量函数向我们希望的方向改进。例如根据我们的判断希望得到更低的能量。基于能量的模型就是通过能量方程定义一个概率分布模型：\n",
    "$$p(x)=\\frac{e^{-E(x)}}{Z}$$\n",
    "此时E为能量函数，p为概率模型，我们要让我们的结果计算出的概率最大（可以看出此时能量应该最小），又因为我们要用梯度下降法求解，所以我们可以给p加上负号-p来让-p最小\n",
    "Z是用来正规化的参数：\n",
    "$$Z=\\sum_x{e^{-E(x)}}$$\n",
    "一般能量函数可以通过随机梯度下降法优化（：the empirical negative log-likelihood of the training data实验负数log相似度）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在线性回归中softmax函数是一个例子\n",
    "$$E(x)= x_{max} - x（1）$$\n",
    "$$p(x) = \\frac{e^{x-x_{max}}}{\\sum_{x\\in D}{e^{x-x_{max}}}}（2）$$\n",
    "下面是梯度下降的过程，目的就是让 negativelog-likelihood最小,如下：\n",
    "$$\\iota(\\theta,D) = -\\frac{1}{N}\\sum{\\log{p(x,\\theta)}}  （3）$$\n",
    "\n",
    "为了让模型更有表现力，我们引入一些属性，但是这些属性是未知的我们用$h$表示，原本已知的属性还是用x表示：那么P写作：\n",
    "$$p(x) = \\sum_h{P(x,h)}=\\sum_h{\\frac{e^{-E(x,h)}}{Z}}$$\n",
    "为了和之前的内容保持一致性，作一下修改：\n",
    "我们另：$-F(x)$代替$-E(x)$:\n",
    "$$F(x)=-\\log{\\sum_h{e^{E(x,h)}}}$$\n",
    "则：\n",
    "$$p(x)=\\frac{e^{-F(x)}}{Z}$$\n",
    "\n",
    "$$Z=\\sum_x{e^{-F(x)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#上边给出了概率分布\n",
    "下面讨论如何让这个含有隐藏属性概率的最大\n",
    "\n",
    "首先我们的negative log-likelihood gradient如公式（3），这个时候需要通过梯度下降法求解，所以我们计算梯度(尝试推倒一下，很容易得到结果)：\n",
    "$$-\\frac{\\partial \\log{p(x)}}{\\partial \\theta} =\\frac{\\partial F(x)}{\\partial \\theta}-\\sum_x{p(x)\\frac{\\partial F(x)}{\\partial \\theta}}$$\n",
    "可以参考的网址：http://www.cnblogs.com/tornadomeet/archive/2013/03/27/2984725.html\n",
    "\n",
    "然而这个导数很难求，所以我们用蒙塔卡罗方法（统计模拟方法，使用随机数来解决计算问题）来进行简化。\n",
    "- 简化第一步：使用期望替代p(X),那么x就是服从p采样规律的\n",
    "现在的问题就是如何得到期望： Markov Chain Monte Carlo methods \n",
    "\n",
    "介绍波尔兹曼机（来源于百度百科）：\n",
    "\n",
    "玻尔兹曼机：BM是一种对称耦合的随机反馈型二值单元神经网络，由可见层和多个隐层组成，网络节点分为可见单元(visible unit)和隐单元(hidden unit)，用可见单元和隐单元来表达随机网络与随机环境的学习模型，通过权值表达单元之间的相关性\n",
    "\n",
    "受限玻尔兹曼机：RBM是一种玻尔兹曼机的变体，但限定模型必须为二分图。模型中包含对应输入参数的输入（可见）单元和对应训练结果的隐单元，图中的每条边必须连接一个可见单元和一个隐单元。（与此相对，“无限制”玻尔兹曼机包含隐单元间的边，使之成为递归神经网络。）这一限定使得相比一般玻尔兹曼机更高效的训练算法成为可能，特别是基于梯度的对比分歧（contrastivedivergence）算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#下面进行RBM的计算描述\n",
    "\n",
    "首先给出明确的能量函数E\n",
    "$$E(v,h)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
